"""
AI åŠ©æ‰‹ API ç«¯ç‚¹

æä¾› AI é©±åŠ¨çš„é£Ÿè°±æ¨èã€è†³é£Ÿè®¡åˆ’ç”Ÿæˆç­‰åŠŸèƒ½ã€‚
æ”¯æŒç”¨æˆ·åœ¨å‰ç«¯åŠ¨æ€é€‰æ‹©AIæœåŠ¡å•† (Google, Openaiï¼ŒDeepSeekç­‰) å¹¶æä¾›å¯†é’¥ã€‚
"""
from typing import Any, Dict, List, Optional
import json
import asyncio

from fastapi import APIRouter, Depends, HTTPException, status, Header, Query
from fastapi.responses import StreamingResponse
import structlog

from app.schemas.ai import ChatRequest, ChatResponse
from app.core.ai_service import get_ai_service, ChatMessage
from app.core.exceptions import AIServiceException

router = APIRouter()
logger = structlog.get_logger()

# --- ä¾èµ–å‡½æ•° ---
async def get_api_credentials(
    x_api_provider: str = Header("google"),
    x_api_key: Optional[str] = Header(None)
) -> Dict[str, str]:
    """ä»è¯·æ±‚å¤´ä¸­æå–AIæœåŠ¡å•†å’ŒAPIå¯†é’¥ã€‚"""
    if not x_api_key:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail=f"An API key for '{x_api_provider}' is required in the 'X-API-Key' header.",
        )
    return {"provider": x_api_provider, "api_key": x_api_key}


# --- API ç«¯ç‚¹ ---
@router.post("/chat", response_model=ChatResponse, summary="AI èŠå¤©åŠ©æ‰‹")
async def chat_with_assistant(
    request: ChatRequest,
    creds: Dict[str, str] = Depends(get_api_credentials),
) -> ChatResponse:
    """
    ä¸ AI åŠ©æ‰‹è¿›è¡Œå¯¹è¯ã€‚

    ç”¨æˆ·é€šè¿‡è¯·æ±‚å¤´é€‰æ‹©æœåŠ¡å•†å¹¶æä¾›å¯†é’¥:
    - `X-API-Provider`: 'google' or 'deepseek' (é»˜è®¤ä¸º 'google')
    - `X-API-Key`: å¯¹åº”çš„APIå¯†é’¥
    """
    try:
        # åŠ¨æ€è·å–AIæœåŠ¡å®ä¾‹
        ai_service = get_ai_service(creds["provider"])
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI è†³é£ŸåŠ©æ‰‹ï¼Œåå«"å°é£Ÿ"ã€‚ä½ çš„ä¸»è¦ä»»åŠ¡æ˜¯ï¼š
1. å¸®åŠ©ç”¨æˆ·åˆ¶å®šå¥åº·çš„è†³é£Ÿè®¡åˆ’ã€‚
2. æ ¹æ®ç”¨æˆ·çš„é£Ÿææ¨èé£Ÿè°±ã€‚
3. æä¾›ä¸“ä¸šçš„è¥å…»å»ºè®®ã€‚
4. è§£ç­”ä¸é£Ÿç‰©ã€çƒ¹é¥ªå’Œå¥åº·é¥®é£Ÿç›¸å…³çš„é—®é¢˜ã€‚

è¯·å§‹ç»ˆä»¥å‹å¥½ã€ä¸“ä¸šã€ä¹äºåŠ©äººçš„è¯­æ°”å›ç­”é—®é¢˜ï¼Œå¹¶å°½å¯èƒ½æä¾›æ¸…æ™°ã€å¯æ“ä½œçš„å»ºè®®ã€‚"""
        
        messages = [ChatMessage(role="system", content=system_prompt)]
        messages.extend([ChatMessage(role=msg.role, content=msg.content) for msg in request.messages])
        
        # ä½¿ç”¨æå–çš„å¯†é’¥è¿›è¡Œè°ƒç”¨
        response = await ai_service.chat_completion(
            messages=messages,
            api_key=creds["api_key"],
            temperature=request.temperature,
        )
        
        return response
        
    except AIServiceException as e:
        # æ•è·æˆ‘ä»¬è‡ªå®šä¹‰çš„AIæœåŠ¡å¼‚å¸¸ï¼Œå‘ç”¨æˆ·è¿”å›æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"AI Service Error ({creds['provider']}): {e.message}"
        )
    except Exception as e:
        # æ•è·æ‰€æœ‰å…¶ä»–æ„å¤–é”™è¯¯
        logger.error("Unexpected Chat Error", error=str(e), provider=creds['provider'], exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An unexpected internal error occurred. Please try again later."
        )


@router.post("/chat/stream", summary="æµå¼AIèŠå¤©å¯¹è¯")
async def stream_chat_with_assistant(
    request: ChatRequest,
    creds: Dict[str, str] = Depends(get_api_credentials),
) -> StreamingResponse:
    """
    æµå¼AIèŠå¤©å¯¹è¯ - è§£å†³è¶…æ—¶é—®é¢˜
    
    ä½¿ç”¨Server-Sent Events (SSE)å®ç°æ–‡å­—é€æ­¥è¾“å‡ºï¼Œé¿å…è¶…æ—¶é—®é¢˜ã€‚
    ç‰¹åˆ«é€‚åˆDeepSeekç­‰éœ€è¦é•¿æ—¶é—´æ€è€ƒçš„æ¨¡å‹ã€‚
    
    å“åº”æ ¼å¼ï¼š
    - type: 'start' | 'chunk' | 'done' | 'error'
    - content: å½“å‰å—å†…å®¹
    - accumulated: ç´¯ç§¯å†…å®¹ï¼ˆå¯é€‰ï¼‰
    """
    try:
        ai_service = get_ai_service(creds["provider"])
        
        async def generate_stream():
            try:
                # å‘é€å¼€å§‹ä¿¡å·
                yield f"data: {json.dumps({'type': 'start', 'content': '', 'provider': creds['provider']}, ensure_ascii=False)}\n\n"
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæµ‹è¯•å¯†é’¥ï¼Œå¦‚æœæ˜¯åˆ™è¿”å›æ¨¡æ‹Ÿå“åº”
                if creds["api_key"] == "test":
                    # æ¨¡æ‹Ÿå“åº”ç”¨äºæµ‹è¯•
                    test_content = "è¿™æ˜¯ä¸€ä¸ªæµå¼å“åº”æµ‹è¯•ã€‚æ‚¨å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œæ­£åœ¨æµ‹è¯•æµå¼è¾“å‡ºåŠŸèƒ½ã€‚"
                    accumulated = ""
                    
                    # æ¨¡æ‹Ÿé€å­—è¾“å‡º
                    for char in test_content:
                        accumulated += char
                        chunk_data = {
                            "type": "chunk",
                            "content": char,
                            "accumulated": accumulated
                        }
                        yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
                        await asyncio.sleep(0.05)  # æ¨¡æ‹Ÿæ‰“å­—å»¶è¿Ÿ
                    
                    # å‘é€å®Œæˆä¿¡å·
                    final_data = {
                        "type": "done", 
                        "content": accumulated,
                        "model": "test-model",
                        "usage": {"tokens": len(test_content)}
                    }
                    yield f"data: {json.dumps(final_data, ensure_ascii=False)}\n\n"
                    return
                
                # çœŸå®AIæœåŠ¡è°ƒç”¨
                # æ„å»ºå®Œæ•´çš„èŠå¤©æ¶ˆæ¯ï¼ŒåŒ…å«ç³»ç»Ÿæç¤ºè¯
                system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI è†³é£ŸåŠ©æ‰‹ï¼Œåå«"å°é£Ÿ"ã€‚ä½ çš„ä¸»è¦ä»»åŠ¡æ˜¯ï¼š
1. å¸®åŠ©ç”¨æˆ·åˆ¶å®šå¥åº·çš„è†³é£Ÿè®¡åˆ’ã€‚
2. æ ¹æ®ç”¨æˆ·çš„é£Ÿææ¨èé£Ÿè°±ã€‚
3. æä¾›ä¸“ä¸šçš„è¥å…»å»ºè®®ã€‚
4. è§£ç­”ä¸é£Ÿç‰©ã€çƒ¹é¥ªå’Œå¥åº·é¥®é£Ÿç›¸å…³çš„é—®é¢˜ã€‚

è¯·å§‹ç»ˆä»¥å‹å¥½ã€ä¸“ä¸šã€ä¹äºåŠ©äººçš„è¯­æ°”å›ç­”é—®é¢˜ï¼Œå¹¶å°½å¯èƒ½æä¾›æ¸…æ™°ã€å¯æ“ä½œçš„å»ºè®®ã€‚æ³¨æ„å†…å®¹åˆ†æ®µï¼Œæ¡ç†æ¸…æ™°ã€‚"""
                
                chat_messages = [ChatMessage(role="system", content=system_prompt)]
                chat_messages.extend([ChatMessage(role=msg.role, content=msg.content) for msg in request.messages])
                
                response = await ai_service.chat_completion(
                    messages=chat_messages,
                    api_key=creds["api_key"],
                    temperature=request.temperature if hasattr(request, 'temperature') else 0.7,
                )
                
                # æ¨¡æ‹Ÿé€æ­¥è¾“å‡ºï¼Œæå‡ç”¨æˆ·ä½“éªŒ
                content = response.content
                accumulated = ""
                
                # æ™ºèƒ½åˆ†è¯ï¼šä¼˜å…ˆæŒ‰å¥å­åˆ†å‰²ï¼Œå…¶æ¬¡æŒ‰è¯åˆ†å‰²
                import re
                sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ\n])', content)
                
                for i, part in enumerate(sentences):
                    if part.strip():
                        accumulated += part
                        
                        chunk_data = {
                            "type": "chunk",
                            "content": part,
                            "accumulated": accumulated
                        }
                        yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
                        
                        # è‡ªé€‚åº”å»¶è¿Ÿï¼šå¥å­é—´ç¨é•¿ï¼Œè¯é—´è¾ƒçŸ­
                        if part in '.!?ã€‚ï¼ï¼Ÿ':
                            await asyncio.sleep(0.1)  # å¥å­ç»“æŸï¼Œç¨ä½œåœé¡¿
                        else:
                            await asyncio.sleep(0.03)  # è¯é—´çŸ­æš‚åœé¡¿
                
                # å‘é€å®Œæˆä¿¡å·
                final_data = {
                    "type": "done", 
                    "content": accumulated,
                    "model": getattr(response, 'model', 'unknown'),
                    "usage": getattr(response, 'usage', {})
                }
                yield f"data: {json.dumps(final_data, ensure_ascii=False)}\n\n"
                
            except AIServiceException as e:
                error_data = {
                    "type": "error",
                    "content": f"AIæœåŠ¡é”™è¯¯ ({creds['provider']}): {str(e)}",
                    "provider": creds['provider']
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                
            except Exception as e:
                logger.error("æµå¼èŠå¤©é”™è¯¯", error=str(e), provider=creds['provider'], exc_info=True)
                error_data = {
                    "type": "error",
                    "content": f"æ„å¤–é”™è¯¯: {str(e)}",
                    "provider": creds['provider']
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
        
        return StreamingResponse(
            generate_stream(),
            media_type="text/event-stream",
            headers={
                # ğŸ”‘ å…³é”®æµå¼å“åº”å¤´ - é˜²æ­¢ä»£ç†ç¼“å†²
                "Content-Type": "text/event-stream; charset=utf-8",
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",  # ç¦ç”¨nginxç¼“å†²
                "Transfer-Encoding": "chunked",  # æ˜ç¡®å¯ç”¨åˆ†å—ä¼ è¾“
                "Pragma": "no-cache",
                "Expires": "0",
                # CORS å¤´
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
                "Access-Control-Allow-Methods": "POST, OPTIONS",
            }
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æµå¼èŠå¤©æœåŠ¡é”™è¯¯: {str(e)}"
        )


# --- å¢å¼ºRAGåŠŸèƒ½ç«¯ç‚¹ ---
@router.post("/rag-search", summary="å¢å¼ºå‹RAGæœç´¢")
async def enhanced_rag_search(
    query: str,
    max_passages: Optional[int] = Query(20, ge=5, le=50, description="æœ€å¤§æ£€ç´¢æ®µè½æ•°"),
    use_advanced_features: bool = Query(True, description="æ˜¯å¦ä½¿ç”¨é«˜çº§RAGåŠŸèƒ½"),
    creds: Dict[str, str] = Depends(get_api_credentials),
) -> Dict[str, Any]:
    """
    å¢å¼ºå‹RAGæœç´¢åŠŸèƒ½
    
    åŸºäºæœ€æ–°RAGç ”ç©¶å®ç°çš„é«˜çº§æœç´¢ï¼ŒåŒ…å«ï¼š
    - å¤šæŸ¥è¯¢å¹¶è¡Œå¤„ç†
    - æ£€ç´¢é‡æ’åº
    - æŸ¥è¯¢ä¼˜åŒ–å’Œåˆ†è§£
    - æ³¨æ„åŠ›å¼•å¯¼çš„ä¸Šä¸‹æ–‡å‰ªæ
    """
    try:
        from app.core.ai_service import get_advanced_rag_service, RAGConfig
        
        # é…ç½®RAGæœåŠ¡
        config = RAGConfig(
            max_retrieved_passages=max_passages,
            use_multi_query=use_advanced_features,
            use_query_decomposition=use_advanced_features,
            use_context_pruning=use_advanced_features
        )
        
        rag_service = get_advanced_rag_service(config)
        
        # æ¨¡æ‹Ÿæ–‡æ¡£åº“ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä»æ•°æ®åº“è·å–ï¼‰
        # è¿™é‡Œä½¿ç”¨ç¤ºä¾‹æ–‡æ¡£ï¼Œå®é™…å®ç°ä¸­åº”è¯¥è¿æ¥åˆ°çœŸå®çš„æ–‡æ¡£æ•°æ®åº“
        sample_documents = [
            {
                "id": "1",
                "content": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›é€ èƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æœºå™¨ã€‚",
                "title": "äººå·¥æ™ºèƒ½æ¦‚è¿°",
                "source": "AIæ•™ç§‘ä¹¦"
            },
            {
                "id": "2", 
                "content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚",
                "title": "æœºå™¨å­¦ä¹ åŸºç¡€",
                "source": "MLæŒ‡å—"
            },
            {
                "id": "3",
                "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒåŸºäºäººå·¥ç¥ç»ç½‘ç»œï¼Œç‰¹åˆ«æ˜¯æ·±å±‚ç¥ç»ç½‘ç»œã€‚",
                "title": "æ·±åº¦å­¦ä¹ ä»‹ç»", 
                "source": "DLæ‰‹å†Œ"
            },
            {
                "id": "4",
                "content": "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸“æ³¨äºè®¡ç®—æœºå’Œäººç±»è¯­è¨€ä¹‹é—´çš„äº¤äº’ã€‚",
                "title": "è‡ªç„¶è¯­è¨€å¤„ç†",
                "source": "NLPæ•™ç¨‹"
            },
            {
                "id": "5",
                "content": "è®¡ç®—æœºè§†è§‰æ˜¯ä¸€ä¸ªè·¨å­¦ç§‘çš„ç§‘å­¦é¢†åŸŸï¼Œç ”ç©¶å¦‚ä½•ä½¿è®¡ç®—æœºä»æ•°å­—å›¾åƒæˆ–è§†é¢‘ä¸­è·å¾—é«˜å±‚æ¬¡çš„ç†è§£ã€‚",
                "title": "è®¡ç®—æœºè§†è§‰",
                "source": "CVæ¦‚è®º"
            }
        ]
        
        # æ‰§è¡Œå¢å¼ºRAGæœç´¢
        result = await rag_service.enhanced_rag_query(
            query=query,
            documents=sample_documents,
            api_key=creds["api_key"],
            provider=creds["provider"],
            max_passages=max_passages
        )
        
        return {
            "status": "success",
            "query": query,
            "answer": result["answer"],
            "sources": result["source_passages"],
            "analysis": result["query_analysis"],
            "performance": result["performance_metrics"],
            "rag_config": {
                "provider": creds["provider"],
                "advanced_features_enabled": use_advanced_features,
                "max_passages": max_passages
            }
        }
        
    except AIServiceException as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"RAG Search Error ({creds['provider']}): {e.message}"
        )
    except Exception as e:
        logger.error("Enhanced RAG search failed", error=str(e), query=query)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="å¢å¼ºRAGæœç´¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        )


@router.post("/recipe-recommendation", summary="æ™ºèƒ½é£Ÿè°±æ¨è")
async def smart_recipe_recommendation(
    query: str = Query(..., description="é£Ÿè°±éœ€æ±‚æè¿°"),
    dietary_restrictions: Optional[List[str]] = Query(None, description="é¥®é£Ÿé™åˆ¶"),
    cuisine_preference: Optional[str] = Query(None, description="èœç³»åå¥½"),
    max_results: int = Query(5, ge=1, le=20, description="æœ€å¤§æ¨èæ•°é‡"),
    creds: Dict[str, str] = Depends(get_api_credentials),
) -> Dict[str, Any]:
    """
    åŸºäºAIçš„æ™ºèƒ½é£Ÿè°±æ¨è
    
    ç»“åˆç”¨æˆ·éœ€æ±‚ã€é¥®é£Ÿé™åˆ¶å’Œåå¥½ï¼Œæä¾›ä¸ªæ€§åŒ–é£Ÿè°±æ¨èã€‚
    """
    try:
        # æ„å»ºæ™ºèƒ½æ¨èæŸ¥è¯¢
        recommendation_query = f"æ¨èé£Ÿè°±ï¼š{query}"
        
        if dietary_restrictions:
            recommendation_query += f"ï¼Œé¥®é£Ÿé™åˆ¶ï¼š{', '.join(dietary_restrictions)}"
        
        if cuisine_preference:
            recommendation_query += f"ï¼Œåå¥½èœç³»ï¼š{cuisine_preference}"
        
        # ä½¿ç”¨AIæœåŠ¡ç”Ÿæˆæ¨è
        ai_service = get_ai_service(creds["provider"])
        
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¥å…»å¸ˆå’Œå¨å¸ˆï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·éœ€æ±‚æ¨èå¥åº·ç¾å‘³çš„é£Ÿè°±ã€‚

è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œæ¨èåˆé€‚çš„é£Ÿè°±ã€‚æ¯ä¸ªæ¨èåº”åŒ…å«ï¼š
1. é£Ÿè°±åç§°
2. ä¸»è¦é£Ÿæ
3. åˆ¶ä½œéš¾åº¦ï¼ˆç®€å•/ä¸­ç­‰/å›°éš¾ï¼‰
4. é¢„è®¡åˆ¶ä½œæ—¶é—´
5. è¥å…»ç‰¹ç‚¹
6. åˆ¶ä½œè¦ç‚¹

è¯·ä»¥JSONæ ¼å¼è¿”å›æ¨èç»“æœï¼š
{
    "recommendations": [
        {
            "name": "é£Ÿè°±åç§°",
            "ingredients": ["é£Ÿæ1", "é£Ÿæ2"],
            "difficulty": "ç®€å•",
            "cook_time": "30åˆ†é’Ÿ",
            "nutrition": "è¥å…»ç‰¹ç‚¹",
            "tips": "åˆ¶ä½œè¦ç‚¹"
        }
    ],
    "reasoning": "æ¨èç†ç”±"
}"""

        messages = [
            ChatMessage(role="system", content=system_prompt),
            ChatMessage(role="user", content=recommendation_query)
        ]
        
        response = await ai_service.chat_completion(
            messages=messages,
            api_key=creds["api_key"],
            temperature=0.7
        )
        
        try:
            import json
            result = json.loads(response.content)
            recommendations = result.get("recommendations", [])
            reasoning = result.get("reasoning", "åŸºäºæ‚¨çš„éœ€æ±‚ç”Ÿæˆçš„æ¨è")
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å›ç­”
            recommendations = []
            reasoning = response.content
        
        return {
            "status": "success",
            "query": query,
            "recommendations": recommendations[:max_results],
            "reasoning": reasoning,
            "filters_applied": {
                "dietary_restrictions": dietary_restrictions,
                "cuisine_preference": cuisine_preference,
                "max_results": max_results
            }
        }
        
    except AIServiceException as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Recipe Recommendation Error ({creds['provider']}): {e.message}"
        )
    except Exception as e:
        logger.error("Recipe recommendation failed", error=str(e), query=query)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="æ™ºèƒ½é£Ÿè°±æ¨èå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        )


# æ³¨æ„ï¼šä¸ºäº†ä¿æŒç¤ºä¾‹ç®€æ´ï¼Œå…¶ä»–éœ€è¦è°ƒç”¨AIçš„ç«¯ç‚¹ï¼ˆå¦‚æ™ºèƒ½æœç´¢ï¼‰æš‚æœªå®ç°åŠ¨æ€åˆ‡æ¢ã€‚
# å®ç°æ–¹å¼ä¸/chatç«¯ç‚¹ç±»ä¼¼ï¼Œå³é€šè¿‡ä¾èµ–æ³¨å…¥è·å–providerå’Œapi_keyï¼Œç„¶åä¼ é€’ç»™AIæœåŠ¡ã€‚
